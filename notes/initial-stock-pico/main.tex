\documentclass{article}

\usepackage{amsmath,amssymb,amsthm}
\usepackage{stmaryrd}
\usepackage{supertabular}
\usepackage{fullpage}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{fancyvrb}
\usepackage{xspace}
\usepackage{hyperref}
\usepackage[normalem]{ulem}

\input{temp/defns}

\renewcommand{\ottkw}[1]{\mathsf{#1}}

\definecolor{dkblue}{rgb}{0,0.1,0.2}
\definecolor{bluegreen}{rgb}{0,0.5,0.5}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{dkred}{rgb}{0.6,0,0}
\definecolor{dkpurple}{rgb}{0.7,0,0.4}
\definecolor{purple}{rgb}{0.7,0,0.7}
\definecolor{olive}{rgb}{0.5, 0.5, 0.0}
\definecolor{teal}{rgb}{0.0,0.5,0.5}

\definecolor{darkred}{rgb}{.8,0,0}
\newcommand{\finish}[1]{{\color{darkred}\em (#1)}}

\newcommand{\comm}[3]{\textcolor{#1}{[#2: #3]}}
\newcommand{\bcp}[1]{{\color{blue}\em (BCP: #1)}}
\newcommand{\amd}[1]{{\color{purple}\em (AMD: #1)}}
\newcommand{\ud}[1]{{\color{cyan}[UD -- #1]}}
\newcommand{\ch}[1]{{\color{dkblue}\em (CH: #1)}}
\newcommand{\aaa}[1]{{\color{dkgreen}\em (AAA: #1)}}
\newcommand{\md}[1]{{\color{dkred}\em (MD: #1)}}
\newcommand{\apt}[1]{{\color{red}\em (APT: #1)}}
\newcommand{\rap}[1]{\comm{magenta}{RAP}{#1}} % Randy

\makeatletter
\newcommand*{\EG}{e.g.,\xspace}
\newcommand*{\IE}{i.e.,\xspace}
\newcommand*{\ETAL}{et al.\xspace}
\newcommand*{\ETC}{etc\@ifnextchar{.}{}{.\xspace}}
\makeatother

\newcommand{\micro}{micro-}
\newcommand{\uP}{\micro policy\xspace}
\newcommand{\uPs}{\micro policies\xspace}
\newcommand{\UPs}{\micro Policies\xspace}
\newcommand{\UPuP}{Abstract \uPP}
\newcommand{\uPuP}{abstract \uPP}
\newcommand{\uPP}{\micro PP\xspace}

\begin{document}

\title{Stock Pico-Machine}
\maketitle

\section{Proposed Short-Term Goals}

\begin{itemize}
\item Goal 1: Developing a set of micro-policies for obtaining {\bf
    kernel protection}, {\bf call stack protection}, as well as {\bf
    (dynamic) basic type and memory safety}, on a simplified model of
  a conventional architecture (\EG MIPS) extended with tags and a TMU.
\item Goal 2: verifying the correctness of these micro-policies with
  respect to a higher-level abstract machine using previous ideas such
  as two-way state refinement\ch{Q: why not bisimulation?} and verified
  structured code generators. There will be at least 3 abstract
  machines on top of each other, illustrating one particular way to do
  vertical/sequential micro-policy composition.
\item Goal 3 (stretch): The kernel virtualizes the services
  of the TMU, so that higher-level micro-policies can be stacked
  on top. Actually building one such higher-level micro-policy on top
  is a stretch goal,
  but maybe if we chose something much simpler than IFC
  (dynamic-sealing or signatures or metadata), this will become more
  realistic in the short term. Otherwise this is future work, and we
  can allude in the paper that that's our longer term plan.
  \ch{The memory protection policy is, however, quite high level
      and would already illustrate this kind of vertical sequential
      composition. I'm getting more and more convinced that we don't
      need anything on top for the moment.}
\item Goal 3' (strech): Implement CFI micro-policy as a replacement
  for memory safety (for instance if memory safety turns out to be too
  expensive in practice) -- might get intern on this
\item Goal 4 (stretch): Extend this to a MIPS I, MIPS II, or MIPS32
  (but still without the floating point stuff; the MIPS32 model
  from RockSalt has 53 instructions and also excludes coprocessor and
  floating point support). Even without this
  extension, would it be fair to call our model a small RISC CPU?
  Could we maybe even call it Featherweight RISC or $\mu$RISC?
  \ch{The $[[AddRule]]$ instruction is very unRISCy, as it
    does a ton of memory reads.} \apt{\ldots $[[AddRule]]$ is already
    a very unrealistic instruction anyway, since it assumes that the 
    cache is infinite.}
  \ch{Something more RISCy would be the TMUL instruction in SAFE that
    loads only one of the fields of the rule at a time, as specified
    by a register (0-8 for M vector fields, 9-17 for R vector fields,
    18 to install the rule); see section 17.2.1 in isaSpec3.pdf}
  \ch{Anyway, this seems easy to fix if we ever get there.}

\bcp{Besides MIPS, we should consider the new RISC-V instruction set from
  Berkeley.}
\item Potential titles:
  \begin{itemize}
  \item Low-level Safety Micro-Policies
  \item Formally Verified Low-level Safety Tagging Schemes
  \end{itemize}
\item Potential targets:
  % \href{http://csf2014.di.univr.it/}{CSF 2014}, 
  % Deadline: February 10, 2014; Abstract: February 3, 2014
  POPL 2015
\end{itemize}

\section{Notes from POPL}

\begin{itemize}
\item don't verify code, just test it wrt spec, use spec in higher-level proofs
\item first target policies:
      (1) kernel protection;
      (2) memory safety (+/- unboxed structs);
\item other potential policies:
  \begin{itemize}
  \item multiple ``users'' / levels of protection
  \item dynamic sealing, closures
  \item call stack protection (+/- stack allocation);
  \item control-flow integrity;
  \item typed assembly language (TAL):
      do they rely on a nice allocation/memory model?
  \item SFI / sandboxing
  \end{itemize}
\end{itemize}

\section{Simplifications}

The real world is much more complicated than what we're doing here.
Things we're simplifying [away]:
\begin{itemize}
\item The concrete machine (instruction set, machine state, etc) is
  very much simplified
\item Bootloading
\item Operating system: device drivers (I/O),
      processes and scheduler (concurrency, protection),
      binary loading (EXE) and dynamic linking (DLL)
\end{itemize}

\section{Jump-and-Link (the ``stackless'' part)}

Because we have a jump-and-link ($[[JAL]]$) instruction we can now separate
Kernel Protection (\autoref{sec:kernel}) from Stack Protection
(\autoref{sec:stack}). Also the hardware doesn't know anything about
the stack and stack protection, and it knows a minimum about kernel
protection.
%
In this jump-and-link world system calls, as well as the
internal kernel subroutine calls are all done with jump-and-link.
%
Cache faults are similar to jump-and-link, just that they use epc (a
special register; as for MIPS exceptions) instead of the regular
return register ra.
%
Using a special register that's {\em not accessible to user mode} is
necessary because TMU faults need to restore all user registers to
their original state; thus overwriting ra is not allowed.
%
Returns from the fault handler are done using a privileged instruction
called $[[JumpEpc]]$; which allows the kernel to return without
consulting the cache; it uses the epc atom verbatim.
%
Returns from system calls are done with a $[[WriteEpc ra]]$ (maybe
right after receiving the call) followed by a $[[JumpEpc]]$ (note: the
kernel can't use $[[Jump ra]]$ because that can fault).
\apt{Why not? What's wrong with a fault there? And anyhow, can't it
be prevented by pre-loading the cache? $[[WriteEpc ra]]$ is not
too pretty; without it, we can view EPC as more like a secret
part of the machine state than a real register, and $[[JumpEpc]]$ 
as meaning ``restart the faulted instruction'' rather than as special
kind of ``return.''}
%
\ch{I think both these alternatives would work fine; adding a rule or
  faulting are more complicated operations than writing a register
  though.  A fourth alternative is ``Copy through R-values'' (see
  discussion in~\autoref{sec:copy-r-vals}).}
%
The kernel and user stack are separated and implemented entirely in
software, and only the user stack is protected using a micro-policy
(the kernel is anyway verified, and it might even not need a stack for
now).

\ch{we can't let the fault handler fault in this world, because on faults
  the $[[epc]]$ gets overwritten, and that would happen even before we
  can safely store it somewhere.}\apt{OK, you've identified an important point:
  built-in stack support would be needed to handle recursive \emph{faults} even
  if we don't write recursive functions. So hopefully we can avoid recursive faults.}
\ch{Is this point still valid, now that we have a way to spill registers to memory?}
%
\ch{In any case, having the fault handler fault is nasty and
  counter-productive, so we should avoid it if possible.}

% \apt{Adding a special [JumpEpc] doesn't seem too bad to me, especially
%   if there is no other way to access the EPC register
%   programmatically. And after all, we have already hardwired the
%   KERNEL pc tag into the faulting rule.}

\section{Concrete Machine Definitions}

A machine state $[[S]]$ has 5 components:
\begin{itemize}
\item memory $[[M]]$ (function from words to atoms)
\item register file $[[R]]$ (function from register numbers to atoms);
  two registers k0 and k1 are only accessible to the kernel
  (i.e. register lookup and update takes the pc label as argument, and
  fails if trying to lookup k0 or k1 and the pc tag is not KERNEL
  \ch{baking this into the semantics seems unavoidable}
  \ch{the Coq developement uses an equivalent formulation})
\item rule cache $[[K]]$ (set of rules; can grow arbitrarily large --
  so no rule is ever evicted from the cache)
\item a special register for the program counter PC=$[[pc@tpc]]$
\item a special register epc storing a return address for the kernel 
\end{itemize}

\noindent
Notes:
\begin{itemize}
\item Programs are stored in memory, and words are decoded into
  instructions using a $[[D(w)]]$ partial function.
  \ch{There was a debate about this; it seems to have died down but
    you can check it in \autoref{sec:sep-instrs}}
\item The initial memory is assumed to store the kernel
  code starting at address 0 (the entry point for the fault handler).
  \ch{It wouldn't be hard to parameterize the machine over this constant.}
\item On this machine the kernel ($[[tpc]] = [[KERNEL]]$) does use the TMU, but
  it always hits in the cache because of the ground rules.
  \ch{this was very hard to ensure in the previous stackful machine
    (if at all possible); however, there the kernel faulting was only
    an efficiency problem, while here we really can't allow the kernel
    to fault}
  \ch{XXX I still wonder if we've actually solved the kernel faulting
    problem, or just
    postponed it to the next micro-policy on top, which will probably
    run again into the same thing. It's not like the fault handlers
    for stack protection or memory safety will be allowed to fault either, so
    again we'll need ground rules, and they will be hard to write. Q:
    Do we have enough mechanism to handle all those cases or not?  For
    instance, for stack protection we might need privileged
    instructions GetTagM and SetTagM that do the same thing as
    GetTag/SetTag, just for memory, so that we can touch arbitrarily
    tagged user memory without faulting. It seems that the programming
    style of the kernel will need to be very defensive; reminiscent a
    bit of white-box poison pill protection.}

\ch{Looking at interrupts on MIPS, one annoying thing is that our fault
  handler can't just ``turn off interrupts'' like the MIPS interrupt
  handlers do, since with tags the semantics of most machine
  instructions is not really defined in the absence of the TMU, and we
  need something very specific and much more sophisticated than the
  ``use a default tag'' strategy in the POPL paper.}
\item There is no separate user/kernel bit; the convention is that
  $[[tpc]]=[[KERNEL]]$ means running in kernel mode, and otherwise
  it's user mode. \ch{There is some additional redundancy, since when
    $[[tpc]]=[[KERNEL]]$ it is also the case that $[[M(pc) =
    _@KERNEL]]$. For a simpler machine without system calls / kernel
    entry points we should be able to remove this redundancy, but
    it's not clear how to do this in the more complex setting.}
\item Some instructions are called ``privileged'', but it's the TMU
  that enforces that they are only called in kernel mode.  \ch{More
    precisely it's the absence of certain rules from the TMU cache
    that does it; so it's a property of the ground rules and an
    invariant of the fault handler}
\item Since we are on a register machine, the fault handler needs to
  perfectly save and restore all user accessible registers before
  returning control to user mode; user mode shouldn't be able to tell
  any difference between a cache hit and a miss.
%
  One challenge here is that the fault handler has to do this without
  faulting even though the registers can have arbitrary tags. Here is
  a solution:
%
  For saving a register (say r1) the fault handler can simply
  first read off the tag of this register to a special kernel register
  (the MIPS has 2 such registers: k0 and k1, and we now have them too)
  (GetTag r1 k0), then it
  can write the tag to kernel memory/stack (Store k0 ksp; Subi ksp 1
  ksp), then erase the tag (Const KERNEL k0; SetTag r1 k0), then write
  the payload to kernel memory/stack (Store r1 ksp; Subi ksp 1
  ksp). The two Stores won't fault because both atoms they write are
  tagged KERNEL. Restoring registers is analogous.
  \apt{Curiously, this is very similar
    to the coding style already adopted in the popl-pico kernel, with
    pack and unpack instructions, because I was using a bunch of Hoare 
    triples that only worked on kernel-tagged data and was too lazy to
    fix them up.}

  \ch{Here is another alternative from the PUMP paper that trades 16
    registers to avoid the spilling overhead: ``To avoid the need to save
    and restore registers, we expand the integer register file with 16
    additional registers that are available only to the miss
    handler. Additionally, the PC of the faulting instruction, the
    rule inputs (opgroup and tags), and the rule outputs appear as
    registers while in miss handler mode (cf. register windows
    [52]). We also add a new miss-handler-return instruction to finish
    installing the concrete rule into the PUMP and return to user
    code.''}\ch{They also add a separate fault handler mode to the
    processor, and only that mode can use these additional registers.}

  \ch{Here is a bit more text from the PUMP paper; it makes it sound
    like this is really easy, but we know for us it was not: ``While
    the processor is in miss-handler mode, the PUMP applies a single,
    hardwired rule: all instructions and data touched by the miss
    handler must be tagged with a predefined miss-handler tag. This
    tagging provides isolation between the miss handler code and data
    and the user code in the same address space. This prevents user
    code from directly calling miss-handler code or manipulating
    miss-handler data structures.  Conversely, it prevents the miss
    handler from accidentally touching user data and code.''}

\item At this point words are integers\ch{naturals in the Coq
    formalization}, but we will not use integers to encode ``large
  things''. We will use pointers to in-memory data structures to
  represent tags. And if this makes people happy, we can also move to
  words being just 32/64 bits, provided it doesn't cause useless
  technical pain.

\end{itemize}


\medskip
\ottgrammartabular{\ottw\ottinterrule}

\ottgrammartabular{
\otta\ottinterrule
\otti\ottinterrule
\ottop\ottinterrule
\ottS\ottinterrule}

\ottgrammartabular{
\ottk\ottinterrule
\ottki\ottinterrule
\ottko\ottinterrule}

\ottdefncstep

\apt{rule(M) and $[[ M[<-ki] ]]$ don't seem to be defined.}
\ch{Indeed, neither is $[[k hit K]]$}
\ch{They are all defined in Coq now}

\section{Baseline SAFEty \uPs}

These policies are meant to recover what was lost when moving from a
SAFE to an un-SAFE machine. They are both very useful in themselves
and serve as a base on which to build more interesting \uPs.
%
The nice thing about this organization is it would allow us to define
a baseline machine abstracting the details away, and everything we do
on top of this machine can have some relevance to both SAFE and stock
architectures.

\subsection{Kernel Protection}
\label{sec:kernel}

\ch{The name ``Kernel Protection'' is probably a bit misleading, since
  all we are protecting is the fault handler and the micro-calls
  (i.e. we are protecting the verified part from the
  unverified part). If there were an unverified {\em operating system
    kernel}, that would run outside the KERNEL tagged, still we might
  want to provide protection for it from the even less trusted user
  code. What would be a better name for this? Micro-policy software
  protection? Self-protection? {\em Self-defense?} Family protection?}

The kernel protection micro-policy aims at:
\begin{enumerate}
\item making sure that the region of memory initially tagged
  $[[KERNEL]]$ or KENTRY is never read or written by user code
  \ch{could as well call this kernel memory protection; it's a much
    simpler thing though than the memory safety micro-policy}
\item making sure that kernel mode is only invoked by a TMU fault or
  by a system call (jump-and-link to an address tagged KENTRY);
  no jumps in the middle of kernel mode\ch{Without this point
  the next point would make little sense}
\item making sure that only kernel mode can call privileged
  instructions (and implicitly, since the kernel never adds stupid
  rules that the user mode can't call privileged instructions --
  adding rules is itself privileged)
\item ``virtualizing'' the services of the TMU so that higher-level
  micro-policies can be built on top. The higher-level micro-policy
  fault handler is just a subroutine that the main fault handler calls
  explicitly using jump-and-link. We will need to devise a little
  calling convention for such calls; \EG using a kernel stack.
  \ch{For simplicity, we left out this point from our current
    formalization}
\end{enumerate}

\sout{The reason we're doing this kind or protection with a micro-policy as
opposed to a separate processor mode is more pedagogical than
practical.}\ch{not so clear; see below} \sout{It shows that micro-policies
can completely replace even the lowest-level protection mechanisms in
an architecture. So only efficiency reasons will make us eventually
switch to a kernel mode, not expressiveness reasons.} \ch{Would a MIPS
  provide any sort of protection for the kernel memory though? One
  would need virtual memory for that, right? Otherwise there's just
  one big address space. So is it the case that a very simple CPU
  would provide point 3 above, but not 1, and maybe not even 2? Point
  4 is anyway just software and specific to what we do here.}

This micro-policy is implemented by: a set of ground rules for kernel
mode, and a fault handler for user mode. Both are written in Coq for
now; see {\tt old/coq/Kernel.v}. For a newer but much simplified
version check out the {\tt kernel\_protection} directory.

\paragraph{Abstract machine for kernel protection micro-policy}
~\ch{FIRST TRY}

The machine states of this abstract machine are more or less the same
as before. The memory\ch{while we don't split the address space, the
  memory will need to attach an additional privilege bit with each
  memory location -- user or kernel}, register file, rule cache, and
PC are unchanged. \ch{The epc register is gone provided we have some
  other way to return from system calls; this abstract machine uses
  $[[Jump ra]]$ to return control back to the main fault handler.}

The higher-level fault handler code is stored at some address X. It
doesn't need to care about saving or restoring user registers; that's
the job of the main fault handler. It can use whatever registers are
allowed by some (yet to be decided) calling convention. The return
from the high-level handler also has to follow this calling
convention. For instance this could be based on a kernel stack,
and/or on a register discipline.

The instructions of this machine are the same as before. \ch{If
  returning from system calls doesn't need to add kernel rules then we
  can remove the AddRule instruction.}

This machine has tags, M-values, R-values, and rule cache that
look exactly the same as the concrete machine's ones. The real rule
cache, however, doesn't store these things directly, but after proper
wrapping. The higher-level fault handler doesn't add rules; it just
returns the R-values to the main fault handler, which first wraps the
tags and only then adds them to the read rule cache. Still the
abstract machine has the impression that these things are added to its
virtual cache. This is the ``virtualization'' part. For instance, say
the higher-level fault handler wants to tag something with 42. The
virtual cache will store a rule using 42, while the real cache will
use a representation of ``USER 42''.

Q: Will this abstract machine see any KERNEL tags?\ch{Yes, we use
  KERNEL as the default tag in the high-level kernel, very similarly
  to the POPL paper} Will it ever see the ``USER'' part of tags? The
main fault handler can hide these things, but what about system calls?
Will those also need to be ``virtualized'' / wrapped? Probably \ldots
%
Basically, at this level the kernel is just a collection of
subroutines + some data space stored in kernel memory.

Added a privilege bit.
Q1: Can the high-level kernel ever fault?
Q2: Under which conditions on high-level kernel code the kernel never faults?
We could just say that at the high level the kernel never faults,
and then prove trace equivalence under the condition that the
highest-level (not yet specified) kernel never causes a fault on the
low level machine.

\ottdefnkastep

\subsection{Call Stack Protection}
\label{sec:stack}

\ch{Separated this out again}

\ch{The MIPS does have registers sp (stack pointer) and fp (frame
  pointer), but they are regular registers accessed by regular
  instructions. It's only a convention that sp points to the top of
  the stack, and fp to the base of the current stack frame.  There
  seem to be
  \href{http://www.linux-mips.org/wiki/WhatsWrongWithO32N32N64}{many
    different calling conventions for MIPS}, but the most commonly
  used
  (\href{http://math-atlas.sourceforge.net/devel/assembly/mipsabi32.pdf}{o32
    ABI}) involves 6 regular registers (4 for arguments, 2 for
  results) and saves the rest on the stack. The things passed in
  registers are still allocated space by the caller on the stack, so
  that the callee can save them there if needed. See
  \href{https://en.wikipedia.org/wiki/Calling_convention\#MIPS}{Wikipedia}
  and
  \href{http://www.cs.iastate.edu/~cs321/MD00565-2B-MIPS32-QRC-01.01.pdf}{Mips32
    Instruction Set Quick Reference} and
  \href{http://people.openrays.org/~comcat/godson/doc/See.MIPS.Run.2nd.en.pdf}{See
    MIPS run Linux} and the
  \href{https://en.wikibooks.org/wiki/MIPS_Assembly/Control_Flow_Instructions}{MIPS
    Assembly WikiBook}.}

\ch{As a first step we would be looking at protecting a call stack
  that doesn't store any other data, only return addresses. However,
  the more realistic case is when the same stack is used for both
  return addresses and function arguments, and maybe even stack
  allocated locals. Since in this model things are mixed up, we would
  also have to mix stack and (some form of) memory protection if we
  want to support it. I think this should be relatively easily doable,
  as long as we don't try to protect the individual fields of C-like
  ``unboxed'' structs. Supporting unboxed structs is hard,
  irrespective of whether the allocation happens on the stack or the
  heap. See below for ideas.}

\subsection{Basic Types and Memory Protection}

\sloppy

\ch{There is more about this micro-policy in: {\tt
    verif/notes/2013-05-memory-protection-no-free} and {\tt
    verif/notes/2013-05-memory-protection}. Since we are on a stock
  machine, we want something closer to the latter (\IE using monotonic
  counter), but I will revert the (stupid) decision to store the base
  and the bounds in the tags, yielding something in between the two.}

\ch{This is also described in {\tt
    users/catalin/internships/micro-policies} (most of Section 2 is
  about this).  Should slowly bring all that in here; after 7 Feb
  maybe?}

\ch{There is also {\tt verif/memory-safety}. It is some incipient (but
  now old) work by Maxime, who took over ideas from David's
  allocator.}
\
\fussy

\ch{Could further split memory protection into a malloc-like allocator
  (in kernel or user space?), and a tag-based memory protection
  mechanism similar to what me and Maxime were working on. The focus
  should be on the latter, not on the former -- if time is tight we
  might even add a malloc instruction to the machine.}

\ch{Distinguishing between pointers and everything else is needed for
  memory protection, so it seems reasonable to also distinguish
  instructions from integers at this point and save ourselves the
  trouble of proving a trivial refinement step.}

\ch{Our basic scheme does not support unboxed structs.  Still, when we
  allocate such a struct we could tag the region of each field with a
  different nonce. The problem is permitting field access via an
  offset pointer, while still stopping buffer overflows. We might need
  to store size and nonce information for each of the fields (i.e. for
  each nonce) to know when to switch to the next nonce when offsetting
  pointers.  We could require that this special kind of offsetting
  happens via a micro-call that can look up the size and nonce
  information in some internal data structure to produce the new nonce
  for the offset pointer. The nice thing about adding such a
  micro-call is that now the programmer (or compiler) can be
  explicitly expressing the intent of selecting fields, and this
  action is distinguishable from just accidentally running over a
  buffer. Finally, this micro-call could probably be cached with
  gfcall, so we wouldn't break efficiency. Basically, the gfcall cache
  would need to remember that nonce1 + offset $\to$ nonce2.}

\ch{Also see the ``Quick question about Watchdog'' email discussion.
  They map unique identifiers (generated on allocation) to pointers
  (the beginning of the region). Benjamin's idea is to allocate
  different nonces to the struct and its fields, and to tag things
  with pairs of nonces (or tuples if things are further nested). Andre
  thinks that ``You don't actually need to represent the separate
  tags, just distinguish at the finest granularity then insert the
  rules suitably for the pointers to capture the inclusion.  That's
  permitted since we can specify the allowed tag sets for rules.  That
  falls out since we aren't just checking for equality.'' The lowest
  granularity seems to match what I say above, but I still don't see
  which rules I would add on allocation to get correct offsetting via
  the TMU (as opposed to just turning offsetting into a micro-call).}

\ch{Q: How does SAFE prevent use-after-free and double-free bugs? A:
  SAFE has no manual memory deallocation, only a garbage collector!
  It's good to keep in mind that the super efficient fat pointer
  mechanism from Andre's CCS 2013 paper only deals with spatial
  violations in the case of a stock architecture.}

\ch{One point we should make here is that our memory safety
  micro-policy provides protection even against no-control data-only
  attacks.}

\section{Higher-level \uPs}

These things could go on top of the baseline safety abstract machine,
but only as a stretch goal, and probably just one of them.

\newcommand{\TAG}[1]{\mbox{\sc #1}}

Here are the \uPs mentioned in the NSF proposal:
\begin{itemize}
  \item IFC
  \item CFI \ch{Nick might work on this}
  \item data race detection
  \item linear pointers, guaranteeing absence of aliasing
  \item refining pointers into a more expressive form of
    ``capabilities'' by tagging them with subsets of
    $\{\TAG{readable}$, $\TAG{writeable}$, $\TAG{jumpable}$,
    $\TAG{callable}\}$
  \item closures (\IE first-class functions, or code pointers together
  with protected local environments)
  \ch{I'm still confused by BCPs proposal of something closure-like}
  \item authorities\ch{{\bf Authority for what?} Some instances are: 
      access control (clearance, canElim), IFC declassification, and
      signing. But then, is there a general notion of ``authority'' that
      works outside of / can be instantiated to these specific scenarios?}
%
    \ch{Ambient authority (a term with rather negative connotations in
      the capabilities world!) can be encoded as a pc tag
      (cf. clearance)? We would need to mix this with the stack
      protection if we wanted lexical authorities (canElim), but it
      doesn't seem impossible. For things like declassification and
      signing unforgeable capabilities are enough, we don't want
      ambient authority in these cases. The TMU can easily give us
      unforgeable capabilities (\EG see memory safety and pointer
      unforgeability; also dynamic sealing can give us capabilities)
      \ldots but how interesting is this anyway? How does it relate
      to the ``refining pointers into capabilities'' point above?}
  \item dynamic sealing~\cite{Morris::73,SumiiPierce01,SumiiPierce2004}
        and trademarks~\cite{Morris::73} (the latter
    can for instance be used to cache the result of dynamic
    contracts)
  \item user-defined metadata (\IE providing system calls for
    setting and getting metadata to arbitrary values)
  \item dynamic type tags for low level languages like C (where the
    main point is to obtain type safety), and for high-level ones like
    Scheme or Ocaml (where the main point is to reduce the cost of
    type safety using hardware acceleration
  \item higher-order contracts~\cite{FindlerF02}
    (recent proposals~\cite{DimoulasFFF11} use sophisticated mechanisms
     for tracking components and assigning blame that could probably
     be encoded as tags)
  \item taint tracking
  \item isolation (in place of VM)
\end{itemize}

\section{Discussions}

\subsection{Two tags per address (location and payload)}

\apt{1. There are many places where tags are really wanted on memory addresses,
rather than or in addition to the tags on the contents (e.g. distinguishing
user data from kernel data, supporting safe memory allocation, etc.)  We are
essentially handling this by converting the tag on the contents into a pair
(address-tag, real-contents-tag).  This is really just a hack, although it
may be an important one. I think it would be clearer to define the machine with
tags on addresses, at least initially, and then explain generically how
the hack can be used to push them into the values --- assuming that is really
desirable from a hardware point of view.}
\ch{I'm actually quite fine with the pair encoding (very often tags
  have to be drawn from some rather complicated datatype, so pairs are
  not a scare for me at all). AFAIK the chances for having two tags
  per memory location in real hardware are basically null (AFAIK even
  one tag per atom is already causing Andre lots of trouble in terms
  of energy consumption; and 100\% memory overhead is already a big
  scare), so the best bet is to do it in the micro-policies that
  actually need it. If this idiom is so generally useful we could
  think of a special ``memory-address-tag-real-contents-split''
  micro-policy, although I'm not convinced this is such an important
  pattern it needs a separate policy.}
\apt{It seems extremely premature to say ``the hardware will or will
not be able to do something.''  I thought the whole point of this exercise
was to investigate and verify clean and useful abstractions for tag-based processing.
Using tags on values to express facts about the addresses in which those
values happen to live may be useful, but it sure ain't clean.
\ch{The hardware doesn't really know whether the tag is on the
  address or the payload or both. It's only the software that
  uses the tag in a particular way.\apt{I don't really understand this.
  Surely from the HW's perspective the tag is definitely on 
  the payload.}}
And it also seems (at least naively) fundamentally inefficient, 
in the sense that tag values have to be recomputed whenever a value moves
in and out of memory -- although perhaps that cost is just in the noise.
But anyway, if we wanted to implement address tags in hardware, there's no reason why
we would have to store a separate tag for each location: large blocks of
contiguous addresses are likely to share the same tag, and address tagging
is relatively static, so a completely different scheme (more akin to a VM page 
directory) might be appropriate, and might not be very expensive.}
\ch{OK, this is indeed an interesting idea, I can think about it more once
  the more urgent problems are solved. I don't think much would change
  conceptually if we went from one model to the other anyway.}

\subsection{Separate instruction memory}
\label{sec:sep-instrs}

\apt{
2. Assuming we can distinguish code memory from data memory (either by adopting
point 1 \ch{I don't really see why we would need 1 for achieving this;
  anyway, distinguishing code memory from data memory could be done in
  a micro-policy.}
or by separating them in the machine state itself, as in the POPL pico 
machine\ch{This is one unrealistic assumption I would very much like to get
  rid off for this machine though.  
  If such a restriction brings some big
  benefit (which I'm not convinced at the moment), it should be
  done by software not by hardware}\apt{Actually, this assumption is not all 
  that unrealistic; e.g. many embedded systems have Harvard architectures. 
  Unless we're actually interested in self-modifying code, it seems like a harmless 
  restriction. As to benefit: the most obvious one is integrity of kernel code, which 
  otherwise has to be maintained as an explicit invariant in proofs. }
  \ch{OK, I guess we would still look more like a simplification to make
    our life easier in the proofs, than to support embedded processors}),
do we really need tags on the instructions themselves? (I realize that
if instructions live in ordinary memory they will have tags anyhow; the question
is whether that is useful.)  In particular, can't we do without KENTRY?
Consider: there is no real harm done if user code jumps
into the middle of kernel code, so long as the pc tag doesn't change to Kernel.
(While the pc tag is still User, we can use rules to prevent access to kernel
data or privileged instructions, which is all that matters.)
So the key thing is to prevent user code from jumping via a code pointer tagged Kernel, 
unless it is one of a known set of entry points deliberately made available to user code
(e.g. at startup or via a previous system call).  All we need to do is use
tag rules to prevent address arithmetic on Kernel-tagged code pointers by
user-mode code.}
\ch{From 10000 feet this seems like a potential alternative to having
  KENTRY-tagged points in the kernel. In which way is this any better
  than the KENTRY solution though? Is there a problem with the KENTRY
  solution which we're trying to solve? Because the instruction memory
  separation + the need to bless these Kernel pointers in advance
  seems like extra overhead that would need to be justified. I also
  don't understand how all these Kernel-blessed pointers could be made
  available via a system call, given that system calls would require
  Kernel-blessed pointers to start with.\apt{Certainly at least one blessed pointer
  would need to be there at user-mode start up}.} 
\apt{I'm not saying there is anything wrong with KENTRY-tags, just that they require 
  tagging of instructions, which might otherwise be avoidable.  
  The idea of accessing kernel routines through capabilities is a fairly
  standard one, and the fact that we could easily use tagging to maintain
  the integrity of the entry point addresses and hence use them directly 
  as capabilities seems kind of cool. I don't see that there is any ``extra overhead.''}
\ch{OK, it seems that the potential goal and design space is larger
  than I considered so far. For now, I would still like to make
  progress on something that looks reasonable, and backtrack on any of
  these open points later on if necessary (\EG for easier
  verification).}

\subsection{Copy through R-values}
\label{sec:copy-r-vals}

\apt{\ldots Perhaps a bolder approach [to JumpEpc] is worth considering.
Have we discussed hardware support
for a generic ``copy through'' kind of pseudo-tag in the R-vector, 
i.e. one which says ``use M-vector tag such-and-so unchanged'' ?
Seems something like this (a) would be pretty easy to implement in HW; 
(b) could potentially help cache utilization a lot.}
\ch{Copy through seems indeed rather easy, but also quite limited.
  What would be a bit more expressive is if we could additionally
  apply a bit mask or something like that. This could help for unboxed
  representations of tags, but not for the current ``tags are
  pointers'' idea. And in any case, the amount of extra processing one
  can do after a cache hit is very limited by the desire not to slow
  down the CPU (cash hits should still take 1 cycle).}

\ch{Copy through would be easy and cool; why not go for it actually?
  Yes, it won't always solve the problem, but it would solve it in
  this case, wouldn't it? We would still need epc because overwriting
  ra on faults is not allowed. But we wouldn't have a problem
  returning out of system calls using a simple $[[Jump ra]]$.}

\ch{One problem with this feature is that it would be very hard to
  virtualize! \IE even if the concrete machine supports it, none of
  the higher-level abstract machines will have this feature}

\subsection{Partial don't-case bitfields?}

\apt{3. To add another run-before-we-can-walk proposal, before I forget it:
perhaps we should sketch out what hardware support for partial don't-care
bitfields within a tag might look like. Seems like this could be a big win
for cache utilization. Of course, as I think we've discussed, it could get quite
complicated to implement in HW.}

\subsection{Multiple tags per atom?}

\rap{If the set of micro-policies is statically known, why not use
  multiple tags per atom?}
%
\ch{Because 1 tag per atom seems already a big deal to ask from the
  HW, I think. Ask Andre.}
%
\ch{And because 1 tag per atom is also sufficient
  expressiveness-wise. And as Andre's PUMP experiments show, in
  certain cases it's also sufficient efficiency-wise.}

\end{document}

% LocalWords:  BCP TODO
